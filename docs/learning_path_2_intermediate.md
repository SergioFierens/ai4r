## ğŸƒâ€â™‚ï¸ AI4R Learning Path #2 â€“ **Intermediate Track**

> *From â€œI can run a modelâ€ to â€œI can tune, extend, and build smart stuff that actually works.â€*

Youâ€™ve trained your first models, tweaked some clusters, maybe even backpropâ€™ed a neural net. Nice.

Now itâ€™s time to go deeper: tune ensembles, shape rewards, mess with distance functions, evolve a Sudoku solverâ€”and crack open a Transformer like itâ€™s no big deal. Letâ€™s go.

### ğŸ› ï¸ Prerequisites

* Youâ€™ve finished the **Beginner Track** (or already speak fluent `require 'ai4r'`)
* Youâ€™ve cloned the repo and can run tests with `bundle exec rake`
* Youâ€™re cool with Git (or brave enough to fake it)

### ğŸŒ³ Module 1 â€“ Forests, Boosting & the Art of Tuning

> ğŸ§  *Learn: tree ensembles are overpoweredâ€”and totally tunable.*

1. Read through `random_forest.rb` and `gradient_boosting.rb`.
2. Copy `compare_all.rb` to `forest_vs_boost.rb`.
3. Play with `num_trees`, `max_depth`, `learning_rate`, etc.
4. Graph accuracy vs. hyperparametersâ€”bonus points for pretty colors.

âœ… You now understand:

* Why RandomForest works out of the box
* Why GradientBoosting can beat itâ€”with tuning

### ğŸ”¬ Module 2 â€“ Distance is a Choice, Not a Fact

> ğŸ§  *Learn: the way your model measures similarity changes everything.*

1. Add `chebyshev` to `lib/ai4r/proximity.rb`
2. Swap it into KMeans or DBSCAN in `kmeans_vs_dbscan.rb`
3. Watch clusters shift dramaticallyâ€”even though the data didnâ€™t

âœ… You now understand:

* How distance metrics control clustering
* That Euclidean isn't always right

### ğŸ§¬ Module 3 â€“ Roll Your Own Genetic Algorithm

> ğŸ§  *Learn: if you can encode a problem, you can evolve a solution.*

1. Peek at `tsp_chromosome.rb`.
2. Build a new chromosome (e.g., 4x4 Sudoku)
3. Plug it into the GA engine and evolve till solved
4. Mutation rate too high? Watch it crash. Too low? It stalls.

âœ… You now understand:

* Chromosome design = creative encoding
* Mutation & crossover = controlled chaos

### ğŸ® Module 4 â€“ Q-Learning, but Make It Smarter

> ğŸ§  *Learn: shaping rewards teaches agents faster than yelling â€œwrong!â€*

1. Start with the grid-world in `docs/reinforcement_learning.md`
2. Add:
   * Negative reward for each step
   * Big bonus for early success
3. Compare convergence speed (how many episodes to learn)

âœ… You now understand:

* Rewards arenâ€™t just feedbackâ€”theyâ€™re a strategy
* Agents learn what you *incentivize*, not what you *want*

### ğŸ¤– Module 5 â€“ A Tiny Transformer That You Can Actually Read

> ğŸ§  *Learn: break down attention, multi-heads, and sequence scalingâ€”line by line.*

1. Open `transformer.rb`â€”yes, read the whole thing
2. Copy the inline example to `mini_transformer.rb`
3. Tweak:
   * Sequence length (10 vs 50)
   * Head count (2 vs 4)
4. Watch parameter count, runtime, and output patterns shift

âœ… You now understand:

* Why attention is expensive
* What multi-head actually means in code

### ğŸ“Š Module 6 â€“ Metrics That Matter

> ğŸ§  *Learn: building your own metric is the most honest way to evaluate.*

1. Check out `bench/common/metrics.rb`
2. Add a `balanced_accuracy` or `f_beta` function
3. Re-run a classifier bench and print your custom metric
4. Push it to your forkâ€”youâ€™re officially contributing

âœ… You now understand:

* Metrics shape how models are judged
* â€œAccuracyâ€ alone isnâ€™t enough

### ğŸ Capstone â€“ Mix & Match Time

Pick a real dataset (UCI, Kaggle, or scrape your own).
Then:

* Train a boosted classifier
* Cluster users or records
* Recommend an action policy using Q-Learning
* Tune, measure, iterateâ€”then ship your notebook or `.rb` file

Document your decisions like this:

1. What youâ€™re solving
2. What you tried
3. What worked (and didnâ€™t)
4. What you learned

âœ… Youâ€™ve combined multiple AI techniques into a single project. Boom.

### ğŸ¥ˆ Youâ€™ve Leveled Up

You now:

* Know how to tune tree-based models
* Customize core behavior (metrics, distances, fitness)
* Build your own problem encodings
* Understand RL reward design
* Actually *get* Transformers
* Can extend and contribute to AI4R itself

Next stop: **Advanced Track** â€” Hidden Markov Models, Monte Carlo Tree Search, custom benchmarks, and serious optimization.

Ready to break things?
