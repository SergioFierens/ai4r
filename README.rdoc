{<img src="https://codeclimate.com/github/SergioFierens/ai4r.png" />}[https://codeclimate.com/github/SergioFierens/ai4r]
{<img src="https://travis-ci.org/olavolav/ai4r.svg?branch=travis-ci-testing" alt="Build Status" />}[https://travis-ci.org/olavolav/ai4r]

= Introduction

This project aims to produce ruby implementations of algorithms covering several Artificial intelligence fields.

= How to install

1. Install the gem:

  gem install ai4r

2. Include require statements in your code:

  require "ai4r"

OneR and Prism now support numeric attributes by discretizing them into a fixed
number of bins. The amount of bins can be controlled with the
`bin_count` parameter.

= Examples

== Using OneR and ZeroR

OneR and ZeroR now expose parameters that let you experiment with different
strategies.  You can list available parameters by calling
`get_parameters_info` on the class.  Parameters can be set with
`set_parameters` before building the model.

  data = Ai4r::Data::DataSet.new.load_csv_with_labels 'examples/classifiers/zero_one_r_data.csv'

  # ZeroR will return the most frequent class.  The ``tie_strategy'' parameter
  # controls what happens when more than one class has the same frequency.
  zero_r = Ai4r::Classifiers::ZeroR.new
  zero_r.set_parameters(:tie_strategy => :random)
  zero_r.build(data)

  # OneR selects the single attribute with the lowest prediction error.  You
  # may force the attribute with ``selected_attribute'' or change the tie break
  # behaviour with ``tie_break''.
  one_r = Ai4r::Classifiers::OneR.new
  one_r.set_parameters(:selected_attribute => 0, :tie_break => :last)
  one_r.build(data)

== SimpleLinearRegression

The regression classifier was renamed ``SimpleLinearRegression''.  It selects
the attribute that minimises mean squared error and derives a slope and
intercept using standard linear regression.  After building the model you can
inspect these coefficients:

  r = Ai4r::Classifiers::SimpleLinearRegression.new.build(data)
  puts r.attribute      # attribute name used for the regression
  puts r.slope          # regression slope
  puts r.intercept      # regression intercept

== LogisticRegression

Binary logistic regression is available as ``LogisticRegression''.  Training
data must have numeric attributes with the last column containing ``0'' or ``1''
labels.  Parameters ``lr'' and ``iterations'' control gradient descent.

  reg = Ai4r::Classifiers::LogisticRegression.new
  reg.set_parameters(lr: 0.5, iterations: 2000).build(data)
  reg.eval([1, 0])  # => 1

== DataSet normalization

Numeric attributes can be normalized with `normalize!`. By default it applies
z-score normalization, but you can also use `:minmax` to scale values to the
`[0,1]` range.

  data = Ai4r::Data::DataSet.new(:data_items => [[1, 10], [2, 20]])
  Ai4r::Data::DataSet.normalized(data, method: :minmax)
  data.normalize!  # in place using z-score

== KMeans random seed

The ``random_seed'' parameter makes KMeans deterministic by seeding Ruby's
RNG before choosing initial centroids. It's often a good idea to normalize
numeric attributes before clustering.

  data = Ai4r::Data::DataSet.new(:data_items => [[1, 2], [3, 4], [5, 6]])
  data.normalize!
  kmeans = Ai4r::Clusterers::KMeans.new
  kmeans.set_parameters(:random_seed => 1).build(data, 2)

== SOM distance metric

Layers and nodes accept an optional ``distance_metric'' parameter.  It controls
how neighbourhood distances are computed.  Supported metrics are
``:chebyshev'' (default), ``:euclidean'' and ``:manhattan''.

  layer = Ai4r::Som::TwoPhaseLayer.new(10, distance_metric: :euclidean)
  som = Ai4r::Som::Som.new(4, 8, 8, layer)
  som.initiate_map

== Clusterer examples

Scripts under `examples/clusterers` showcase additional features:

* `kmeans_custom_example.rb` runs KMeans with a custom distance function and a
  fixed seed.  It prints the final SSE and how many iterations were needed.
* `hierarchical_dendrogram_example.rb` builds a hierarchical clusterer and
  outputs a simple dendrogram using the recorded tree.

== Checking eval availability

Some hierarchical algorithms cannot classify new items once built.  Use
`supports_eval?` to verify before calling `eval`:

  clusterer = Ai4r::Clusterers::AverageLinkage.new.build(data, 2)
  clusterer.supports_eval? # => false

= Documentation

Tutorials for genetic algorithms, ID3 decision trees and neural networks are available in the +docs/+ directory.

Tutorials for genetic algorithms, ID3 decision trees, Hyperpipes, neural networks, a Naive Bayes classifier and the IB1 classifier are available in the +docs/+ directory.
Documentation for the PRISM rule induction algorithm is available in [docs/prism.md](docs/prism.md).

= Disclaimer

This software is provided "as is" and without any express or implied warranties,
including, without limitation, the implied warranties of merchantibility and
fitness for a particular purpose.
